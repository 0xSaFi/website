---
layout: obsolete
title: "Accessibility: Test Plan"
permalink: /old_site/Accessibility:_Test_Plan/
redirect_from:
  - /Accessibility:_Test_Plan/
---

<h1>Accessibility: Test Plan</h1>

<table id="toc" class="toc"><tr><td><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Scope"><span class="tocnumber">1</span> <span class="toctext">Scope</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#References"><span class="tocnumber">2</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#QA_Meetings"><span class="tocnumber">3</span> <span class="toctext">QA Meetings</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Definitions"><span class="tocnumber">4</span> <span class="toctext">Definitions</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Test_plan"><span class="tocnumber">5</span> <span class="toctext">Test plan</span></a>
<ul>
<li class="toclevel-2 tocsection-6"><a href="#Purpose"><span class="tocnumber">5.1</span> <span class="toctext">Purpose</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Outline"><span class="tocnumber">5.2</span> <span class="toctext">Outline</span></a>
<ul>
<li class="toclevel-3 tocsection-8"><a href="#Test_plan_identifier"><span class="tocnumber">5.2.1</span> <span class="toctext">Test plan identifier</span></a></li>
<li class="toclevel-3 tocsection-9"><a href="#Introduction"><span class="tocnumber">5.2.2</span> <span class="toctext">Introduction</span></a></li>
<li class="toclevel-3 tocsection-10"><a href="#Test_items"><span class="tocnumber">5.2.3</span> <span class="toctext">Test items</span></a></li>
<li class="toclevel-3 tocsection-11"><a href="#Software_risk_issues"><span class="tocnumber">5.2.4</span> <span class="toctext">Software risk issues</span></a></li>
<li class="toclevel-3 tocsection-12"><a href="#Features_to_be_tested"><span class="tocnumber">5.2.5</span> <span class="toctext">Features to be tested</span></a>
<ul>
<li class="toclevel-4 tocsection-13"><a href="#WinForms"><span class="tocnumber">5.2.5.1</span> <span class="toctext">WinForms</span></a></li>
<li class="toclevel-4 tocsection-14"><a href="#Moonlight"><span class="tocnumber">5.2.5.2</span> <span class="toctext">Moonlight</span></a></li>
<li class="toclevel-4 tocsection-15"><a href="#UIA_Provider"><span class="tocnumber">5.2.5.3</span> <span class="toctext">UIA Provider</span></a></li>
<li class="toclevel-4 tocsection-16"><a href="#UIA.2FATK_Bridge"><span class="tocnumber">5.2.5.4</span> <span class="toctext">UIA/ATK Bridge</span></a></li>
<li class="toclevel-4 tocsection-17"><a href="#UIA.2FAT-SPI_Bridge"><span class="tocnumber">5.2.5.5</span> <span class="toctext">UIA/AT-SPI Bridge</span></a></li>
<li class="toclevel-4 tocsection-18"><a href="#UIA_Client_API"><span class="tocnumber">5.2.5.6</span> <span class="toctext">UIA Client API</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-19"><a href="#Features_not_to_be_tested"><span class="tocnumber">5.2.6</span> <span class="toctext">Features not to be tested</span></a></li>
<li class="toclevel-3 tocsection-20"><a href="#Approach"><span class="tocnumber">5.2.7</span> <span class="toctext">Approach</span></a>
<ul>
<li class="toclevel-4 tocsection-21"><a href="#WinForms_Testing"><span class="tocnumber">5.2.7.1</span> <span class="toctext">WinForms Testing</span></a></li>
<li class="toclevel-4 tocsection-22"><a href="#Moonlight_Testing"><span class="tocnumber">5.2.7.2</span> <span class="toctext">Moonlight Testing</span></a></li>
<li class="toclevel-4 tocsection-23"><a href="#UIAutomation_Client_API_Testing"><span class="tocnumber">5.2.7.3</span> <span class="toctext">UIAutomation Client API Testing</span></a></li>
<li class="toclevel-4 tocsection-24"><a href="#General_Guidelines"><span class="tocnumber">5.2.7.4</span> <span class="toctext">General Guidelines</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-25"><a href="#Item_pass.2Ffail_criteria"><span class="tocnumber">5.2.8</span> <span class="toctext">Item pass/fail criteria</span></a></li>
<li class="toclevel-3 tocsection-26"><a href="#Suspension_criteria_and_resumption_requirements"><span class="tocnumber">5.2.9</span> <span class="toctext">Suspension criteria and resumption requirements</span></a></li>
<li class="toclevel-3 tocsection-27"><a href="#Test_deliverables"><span class="tocnumber">5.2.10</span> <span class="toctext">Test deliverables</span></a></li>
<li class="toclevel-3 tocsection-28"><a href="#Testing_preparation_and_setup"><span class="tocnumber">5.2.11</span> <span class="toctext">Testing preparation and setup</span></a></li>
<li class="toclevel-3 tocsection-29"><a href="#Environmental_needs"><span class="tocnumber">5.2.12</span> <span class="toctext">Environmental needs</span></a></li>
<li class="toclevel-3 tocsection-30"><a href="#Responsibilities"><span class="tocnumber">5.2.13</span> <span class="toctext">Responsibilities</span></a>
<ul>
<li class="toclevel-4 tocsection-31"><a href="#Test_Suit"><span class="tocnumber">5.2.13.1</span> <span class="toctext">Test Suit</span></a></li>
<li class="toclevel-4 tocsection-32"><a href="#WinForms_2"><span class="tocnumber">5.2.13.2</span> <span class="toctext">WinForms</span></a></li>
<li class="toclevel-4 tocsection-33"><a href="#MoonLight_2"><span class="tocnumber">5.2.13.3</span> <span class="toctext">MoonLight</span></a></li>
<li class="toclevel-4 tocsection-34"><a href="#UIAutomation_Client_API"><span class="tocnumber">5.2.13.4</span> <span class="toctext">UIAutomation Client API</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-35"><a href="#Staffing_and_training_needs"><span class="tocnumber">5.2.14</span> <span class="toctext">Staffing and training needs</span></a>
<ul>
<li class="toclevel-4 tocsection-36"><a href="#Training_Plan"><span class="tocnumber">5.2.14.1</span> <span class="toctext">Training Plan</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-37"><a href="#Schedule"><span class="tocnumber">5.2.15</span> <span class="toctext">Schedule</span></a>
<ul>
<li class="toclevel-4 tocsection-38"><a href="#WinForms_3"><span class="tocnumber">5.2.15.1</span> <span class="toctext">WinForms</span></a></li>
<li class="toclevel-4 tocsection-39"><a href="#MoonLight_3"><span class="tocnumber">5.2.15.2</span> <span class="toctext">MoonLight</span></a></li>
<li class="toclevel-4 tocsection-40"><a href="#Client_API"><span class="tocnumber">5.2.15.3</span> <span class="toctext">Client API</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-41"><a href="#Risks_and_contingencies"><span class="tocnumber">5.2.16</span> <span class="toctext">Risks and contingencies</span></a></li>
<li class="toclevel-3 tocsection-42"><a href="#Approvals"><span class="tocnumber">5.2.17</span> <span class="toctext">Approvals</span></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</td></tr></table>
<h2> <span class="mw-headline" id="Scope">Scope</span></h2>
<p>A test plan for the Accessibility team's efforts in bringing accessibility to mono by implementing the managed UI Automation framework.
</p>
<h2> <span class="mw-headline" id="References">References</span></h2>
<p><a href="{{site.baseurl}}/Accessibility:_Test_Plan" title="Accessibility: Test Plan">Product Test Plan</a> (current page)<br />
<a href="{{site.baseurl}}/Accessibility:_Test_Case_Specification" title="Accessibility: Test Case Specification">Product Test Case Specification</a><br />
<a href="{{site.baseurl}}/Accessibility:_Test_Log" title="Accessibility: Test Log">Product Test Log</a><br />
<a href="{{site.baseurl}}/Accessibility:_Test_Summary" title="Accessibility: Test Summary">Product Test Summary</a><br />
<a href="{{site.baseurl}}/Accessibility:_Bug_Specification" title="Accessibility: Bug Specification">Product Bug Specification</a><br />
<a href="{{site.baseurl}}/Accessibility:_Test_Coding_Standard" title="Accessibility: Test Coding Standard">Product Test Coding Standard</a><br />
<a href="{{site.baseurl}}/Accessibility" title="Accessibility">Product Home</a><br />
</p><p>The <a href="http://www.mono-project.com/Accessibility:_Roadmap" class="external text" rel="nofollow">Product roadmap</a><br />
The <a href="http://www.mono-project.com/Accessibility#Architecture" class="external text" rel="nofollow">Architecture overview</a><br />
<a href="http://www.novell.com/news/press/microsoft-and-novell-celebrate-year-of-interoperability-expand-collaboration-agreement" class="external text" rel="nofollow">The Novell &amp; Microsoft announcement</a> to create cross-platform accessibility framework
</p>
<h2> <span class="mw-headline" id="QA_Meetings">QA Meetings</span></h2>
<p><a href="{{site.baseurl}}/Accessibility:_QA_Meetings_2008_Jun_5" title="Accessibility: QA Meetings 2008 Jun 5"> June 5 2008</a><br />
<a href="{{site.baseurl}}/Accessibility:_QA_Meetings_2008_Aug_13" title="Accessibility: QA Meetings 2008 Aug 13"> August 13 2008</a><br />
<a href="{{site.baseurl}}/Accessibility:_QA_Meetings_2009_Mar_25" title="Accessibility: QA Meetings 2009 Mar 25"> Mar 25 2009</a><br />
<a href="{{site.baseurl}}/Accessibility:_QA_Meetings_2009_May_20" title="Accessibility: QA Meetings 2009 May 20"> May 20 2009</a><br />
</p><p>No meetings scheduled
</p>
<h2> <span class="mw-headline" id="Definitions">Definitions</span></h2>
<p><a href="http://msdn2.microsoft.com/en-us/accessibility/bb892133.aspx" class="external text" rel="nofollow">UIA</a>---Microsoft UI Automation.  A managed code application programming interface (API), exposing user interface controls for test automation and assistive technology. Part of the .NET framework starting at 3.0. Successor of MSAA (Microsoft Active Accessibility)<br /><br />
UIA Clients---Applications such as screen readers and testing frameworks written in managed code (e.g., C#/VB).<br /><br />
UIA Providers---UI implementations or application controls such as checkboxes. Written in managed code or C/C++.<br /><br />
AT---Assistive technology. A generic term that includes assistive, adaptive, and rehabilitative devices and the process used in selecting, locating, and using them.<br /><br />
AT-SPI---A toolkit neutral way of providing accessibility facilities in applications. AT-SPI can also be used to automate testing of user interfaces. AT-SPI is currently supported by GTK+2, JAVA/Swing, Mozilla, and StarOffice/OpenOffice. For our product, AT-SPI will act as the equivalent of the UIA core.<br /><br />
ATK---Accessibility toolkit.  A developer toolkit that allows programmers to use common GNOME accessibility features in their applications.<br /><br />
ATK/UIA Bridge---Mapping of ATK to the UIA provider APIs.<br /><br />
UIA/at-spi Bridge---Mapping of AT-SPI to the UIA provider APIs.<br /><br />
<a href="{{site.baseurl}}/WinForms" title="WinForms">WinForms</a>---One of the many GUI Toolkits for use with Mono, working towards compatibility with Microsoft's System.Windows.Forms.<br /><br />
<a href="{{site.baseurl}}/Moonlight" title="Moonlight">Moonlight</a>---The Mono-based implementation of Silverlight.<br /><br />
<a href="http://live.gnome.org/Accerciser" class="external text" rel="nofollow">Accerciser</a>---An interactive Python accessibility explorer for the GNOME desktop. It uses AT-SPI to inspect and control widgets, allowing you to check if an application is providing correct information to assistive technologies and automated test frameworks.<br /><br />
<a href="http://live.gnome.org/Orca" class="external text" rel="nofollow">Orca</a>---Open source scriptable screen reader. Using various combinations of speech, braille, and magnification, Orca helps provide access to applications and toolkits that support the AT-SPI (e.g., the GNOME desktop).<br /><br />
<a href="http://www.codeplex.com/Wiki/View.aspx?ProjectName=IronPython" class="external text" rel="nofollow">IronPython</a>---Implementation of the Python programming language, targeting .NET and Mono. It makes .NET libraries easily available to Python programmers, while maintaining full compatibility with the Python language.<br /><br />
<a href="http://www.python.org" class="external text" rel="nofollow">CPython</a>---The default, most-widely used implementation of the Python programming language. It is written in C, hence the name CPython.<br /><br />
<a href="http://medsphere.org/projects/strongwind" class="external text" rel="nofollow">Strongwind</a>---A GUI test automation framework inspired by dogtail. Strongwind is object-oriented and extensible. Strongwind is written in Python and uses the pyatspi library to manipulate and query the state of applications.
</p>
<h2> <span class="mw-headline" id="Test_plan">Test plan</span></h2>
<h3> <span class="mw-headline" id="Purpose">Purpose</span></h3>
<p>This document is a comprehensive test strategy to be used by testers to ensure proper and exhaustive testing.  It also acts as a reference for all stakeholders wishing to obtain information on current and past testing efforts.
</p>
<h3> <span class="mw-headline" id="Outline">Outline</span></h3>
<h4> <span class="mw-headline" id="Test_plan_identifier"><u>Test plan identifier</u></span></h4>
<p>The purpose of this section is to identify the current and previous versions of the test plan, its level, and the version of software it pertains to.
</p>
<table class="wikitable" border="1" style="text-align:center">

<tr>
<th> ID
</th>
<th> Level
</th>
<th> Software Version
</th>
<th> Modify Time
</th>
<th> Author
</th></tr>
<tr>
<td> Accessibility-TP-V0.1
</td>
<td> Draft
</td>
<td> N/A
</td>
<td> 03-25-2008
</td>
<td> Brian &amp; Calen
</td></tr>
<tr>
<td> Accessibility-TP-V1.0
</td>
<td> Initial Release
</td>
<td> N/A
</td>
<td> 03-25-2008
</td>
<td> Brian &amp; Calen
</td></tr>
<tr>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr>
</table>
<h4> <span class="mw-headline" id="Introduction"><u>Introduction</u></span></h4>
<p>Testing efforts will be related to the project goals, which are:
</p>
<ul><li>Make mono <a href="{{site.baseurl}}/WinForms" title="WinForms">WinForms</a> accessible. All WinForms currently supported by mono.
</li><li>Make <a href="{{site.baseurl}}/Moonlight" title="Moonlight">Moonlight</a> accessible
</li><li>Allow <a href="{{site.baseurl}}/UI_Automation" title="UI Automation"> UI Automation</a> based Accessibility Technologies to run on Linux
</li></ul>
<p>This plan includes integration, system, and acceptance testing.  Unit testing is excluded, as it is being managed by individual developers.
</p><p>Integration testing to test WinForms accessibility via UIA provider and UIA/ATK bridge to AT-SPI is scheduled to be completed in 2008.<br /><br />
System testing will be performed in 2009.  Testing will be performed using an AT management tool to test the client and provider.<br /><br />
Acceptance testing will be performed later in 2009 before the product is released.  During system testing, the product should be tested in its entirety from the end user's point of view.<br /><br />
</p>
<h4> <span class="mw-headline" id="Test_items"><u>Test items</u></span></h4>
<p>According to the project plan, test items is below:
</p><p>Test Components:
</p>
<table class="wikitable" border="1" style="text-align:center">

<tr>
<th> Test Items
</th>
<th> Priority(S1/S2/S3)
</th>
<th> Schedule
</th></tr>
<tr>
<td> Winforms Providers
</td>
<td> S1
</td>
<td>
</td></tr>
<tr>
<td> Moonlight Providers
</td>
<td> S1
</td>
<td>
</td></tr>
<tr>
<td> Core-Provider
</td>
<td> S1
</td>
<td>
</td></tr>
<tr>
<td> Core-Client
</td>
<td> S1
</td>
<td>
</td></tr>
<tr>
<td> ATSPIBridge
</td>
<td> S1
</td>
<td>
</td></tr>
</table>
<h4> <span class="mw-headline" id="Software_risk_issues"><u>Software risk issues</u></span></h4>
<p><i>This section describes any risks resulting from lack of time and/or resources.</i>
</p>
<ul><li>frequent changes to requirements and/or design.
</li><li>loss of support from Novell/Microsoft upper management
</li></ul>
<p>Developers are also tracking problems they encounter:
</p>
<ul><li><a href="http://www.mono-project.com/Accessibility:_UiaAtkBridge#Problems_found" class="external text" rel="nofollow">UIA/ATK Bridge Problems</a>
</li></ul>
<h4> <span class="mw-headline" id="Features_to_be_tested"><u>Features to be tested</u></span></h4>
<p><i>Abstraction of test items. What will be tested from the user or customer point of view.</i>
</p>
<h5> <span class="mw-headline" id="WinForms">WinForms</span></h5>
<p>We plan to test all Functionalities of WinForms controls those have been mentioned in <a href="http://monouia.wik.is/Provider_Functional_Specification" class="external text" rel="nofollow">Provider_Functional_Specification</a> and <a href="http://mono-project.com/Accessibility:_Bridge_Functional_Specification" class="external text" rel="nofollow">Bridge_Functional_Specification</a>.
</p><p>According to Q2 2008 of the <a href="{{site.baseurl}}/Accessibility#Roadmap_roadmap" title="Accessibility">Accessibility#Roadmap roadmap</a>, testing contents need relate with below info:
</p>
<ul><li>The WinForms sheet in <a href="http://www.mono-project.com/Accessibility:_Test_Plan_WinForms_Controls" class="external text" rel="nofollow">WinForms Controls list</a> defines which WinForms controls will be implemented and therefore need to be tested.
</li><li>Create WinForms application samples to test against.  These application samples should be written in IronPython.  Our sample applications can be found at <a href="svn://anonsvn.mono-project.com/source/trunk/uia2atk" class="external free" rel="nofollow">svn://anonsvn.mono-project.com/source/trunk/uia2atk</a>  /test/samples.  Some C# samples (that can be translated) can be checked out via svn from <a href="http://anonsvn.mono-project.com/viewvc/trunk/winforms" class="external free" rel="nofollow">http://anonsvn.mono-project.com/viewvc/trunk/winforms</a>.
</li><li>Test WinForms applications samples using Accerciser to ensure that the samples are accessible.
</li><li>Test WinForms applications samples using Orca to ensure that the samples are accessible.
</li><li>Write automated scripts using Strongwind to verify accessibility of all WinForms controls.
</li></ul>
<p>Stuffs for WinForms test:
</p>
<ul><li>Define what WinForms controls will be tested
</li><li>Define what WinForms application samples will be used
</li><li>Create custom WinForms applications in IronPython
</li><li>Test WinForms application samples with Accerciser to ensure accessibility
</li><li>Test WinForms application samples with Orca to ensure accessibility
</li><li>Create automated test suite in Python with StrongWind framework to ensure accessibility of all WinForms controls
</li><li>Review automated test suites with each other by using <a href="http://reviews.mono-a11y.org/" class="external text" rel="nofollow">Review_Board</a>, Please read <a href="http://www.review-board.org/docs/manual/dev/users/#usersguide" class="external text" rel="nofollow">UsersGuide</a> before you use it.
</li></ul>
<h5> <span class="mw-headline" id="Moonlight">Moonlight</span></h5>
<p>According to <a href="http://msdn.microsoft.com/en-us/library/cc645072%28VS.95%29.aspx" class="external text" rel="nofollow">Silverlight doc</a> that we have 32 Moonlight controls will be implemented, so we should test 32 controls whether they are accessible. (there might be some differences between silverlight and moonlight, it's not sure yet)
</p>
<ul><li> The Moonlight sheet in <a href="http://spreadsheets.google.com/ccc?key=0AkMHBvpvUyGOcHd5ZHk3UzNYUFRCVFJTOW5fb0JqSkE&amp;hl=EN" class="external text" rel="nofollow">Moonlight Controls List</a> defines what Moonlight controls should be tested.
</li><li> Moonlight test sample will be written in C# and xaml
</li><li> Moonlight test script will be written in Python with Strongwind framework
</li></ul>
<p>Testing for Moonlight test:
</p>
<ul><li>Define what Moonlight elements will be tested
</li><li>Define what Moonlight application samples will be used
</li><li>Create or reuse Moonlight applications
</li><li>Test Moonlight application samples with Accerciser(against Firefox web browser?)
</li><li>Create automated test suite to ensure the accessibility of all Moonlight elements
</li><li>Test Moonlight application samples with Orca
</li></ul>
<h5> <span class="mw-headline" id="UIA_Provider">UIA Provider</span></h5>
<ul><li>Define what functional should be test for each control according to <a href="http://monouia.wik.is/Provider_Functional_Specification" class="external text" rel="nofollow">Provider_Functional_Specification</a>
</li><li>Test each controls to ensure provider interface is implemented
</li></ul>
<h5> <span class="mw-headline" id="UIA.2FATK_Bridge">UIA/ATK Bridge</span></h5>
<ul><li>Define what functional should be test for each control according to <a href="http://mono-project.com/Accessibility:_Bridge_Functional_Specification" class="external text" rel="nofollow">Bridge_Functional_Specification</a>
</li><li>Test each controls to ensure ATK interface is showing correct information
</li></ul>
<h5> <span class="mw-headline" id="UIA.2FAT-SPI_Bridge">UIA/AT-SPI Bridge</span></h5>
<ul><li>Test each controls to ensure AT-SPI is showing correct information
</li></ul>
<h5> <span class="mw-headline" id="UIA_Client_API">UIA Client API</span></h5>
<p>UIA verify is an open source test tool like UISpy running on Windows, developer can use it to watch controls properties and patterns, it will be posted running on Linux, so we will need to make sure the behavior of UIA verify on Linux is match to Windows.
</p><p>White is a thin wrapper of UIAutomationClient that is like Strongwind wrap pyatspi, developer will post it running on Linux, so we will use White framework to write tests for Client API to against Winforms, Moonlight,  Gtk+ applications. The work path of using White to test application is:
C# -&gt; White -&gt; UIAutomationClient -&gt; DBus -&gt; UIA -&gt; applications(Winforms/Moonlight/GTK+)
</p><p>Testing for UIAutomation Client API test:
</p><p>-Winforms
</p>
<ul><li>Design UserCases of the real application(We will use KeePass), analyze the coverage of each ControlPattern's properties and methods
</li><li>Write tests using White in C# for the real application
</li><li>Run the tests on Linux to make sure they do the same behavior as on Windows
</li></ul>
<p>-Moonlight
</p>
<ul><li>Design UserCases of the real application, analyze the coverage of each ControlPattern's properties and methods
</li><li>Write tests using White in C# for Moonlight apps on Windows
</li><li>Run the tests on Linux to make sure they do the same behavior as on Windows
</li><li>Test UIA verify on Linux to make sure the behavior is match with on Windows. UIA verify have provided automation tests, we can run all the applications on Linux and Windows, then to verify we get the same result of how many tests pass or fail
</li></ul>
<p>-GTK+
</p>
<ul><li>Design UserCases of the real application(gedit?), analyze the coverage of each ControlPattern's properties and methods
</li><li>Write tests using White for GTK+ apps
</li><li>Run the tests on Linux to make sure Client API is worked for GTK+ app
</li></ul>
<h4> <span class="mw-headline" id="Features_not_to_be_tested"><u>Features not to be tested</u></span></h4>
<p><i>Any features that will not be tested and why.  Decisions not to test a feature should be based on priority and risk.  If a feature will not be tested, define what features (class, methods, properties) will not be tested.</i>
</p><p>At this time we plan to test all features exhaustively.
</p>
<h4> <span class="mw-headline" id="Approach"><u>Approach</u></span></h4>
<p><i>A description of how and where testing will be performed and explain any issues that have a major impact on the success of testing and ultimately on the project.</i>
</p>
<h5> <span class="mw-headline" id="WinForms_Testing">WinForms Testing</span></h5>
<p>The accessibility of WinForms applications will be tested using Strongwind tests and WinForms sample applications.  A test harness has also been developed to facilitate the execution and logging of a suite of tests.  For more information see the <a href="{{site.baseurl}}/Accessibility:_Testing_Howto#WinForms" title="Accessibility: Testing Howto">WinForms portion</a> of the <a href="{{site.baseurl}}/Accessibility:_Testing_Howto" title="Accessibility: Testing Howto">Testing Howto</a>.
</p>
<h5> <span class="mw-headline" id="Moonlight_Testing">Moonlight Testing</span></h5>
<p>The accessibility of Moonlight applications will be tested using Strongwind tests and Moonlight sample applications. Moonlight application will be writted in C#. For more information see the <a href="{{site.baseurl}}/Accessibility:_Testing_Howto#Moonlight" title="Accessibility: Testing Howto">Moonlight portion</a> of the <a href="{{site.baseurl}}/Accessibility:_Testing_Howto" title="Accessibility: Testing Howto">Testing Howto</a>.
</p>
<h5> <span class="mw-headline" id="UIAutomation_Client_API_Testing">UIAutomation Client API Testing</span></h5>
<p>WinForms, Moonlight and Gtk+ applications will be tested using White framework. For more information of how to create White test please see <a href="{{site.baseurl}}/Accessibility:_Testing_Howto#ClientAPI" title="Accessibility: Testing Howto">ClientAPI portion</a> of the <a href="{{site.baseurl}}/Accessibility:_Testing_Howto" title="Accessibility: Testing Howto">Testing Howto</a>.
</p>
<h5> <span class="mw-headline" id="General_Guidelines">General Guidelines</span></h5>
<ul><li>All testers shall be on the team IRC channel (#mono-a11y on irc.gimp.org) during work hours.<br /><br />
</li><li>Tests shall be automated whenever possible.  Time constraint is not a good excuse not to automate.<br /><br />
</li><li>Test plan will be developed using the IEEE Std. 829-1998 Standard for Software Test Documentation.<br /><br />
</li><li>All bugs shall be logged in <a href="https://bugzilla.novell.com" class="external text" rel="nofollow">Bugzilla</a> at the time they are found.<br /><br />
</li><li>Bugzilla can be accessed from <a href="http://bugzilla.novell.com" class="external free" rel="nofollow">http://bugzilla.novell.com</a> with Novell account.  The product category is "UI Automation," which can be found under the Mono classification.<br /><br />
</li><li>When a bug's status is changed to RESOlVED or VERIFIED in Bugzilla, the reporter of the bug should change the bug's status to CLOSED or reopen the bug as soon as possible. If the person who reported the bug verifies the bug, the bug can be closed without having its status changed to VERIFIED. A bug should not be closed by someone who did not report the bug unless the reporter is unavailable.<br /><br />
</li><li>Types of system testing include function, performance, security, load, reliability, usability, documentation testing.<br /><br />
</li><li>Acceptance criteria for patch acceptance: Before a patch is accepted, a QA engineer must ensure that the patch submitted from developer passes QA testing.   A build engineer must ensure the patch builds properly and meets packaging standards. QA and build engineers will then create a patch acceptance report, and the patch can be included in the product.<br /><br />
</li><li>Testers may perform system testing on the product only after development has verified that they have completed a development milestone and the build team has created a stable release.<br /><br />
</li><li>WinForms samples will be created in C#, Boo, or IronPython(here we chose IronPython). Automation scripts, that test the accessibility of the WinForms apps will be created in CPython.  <a href="{{site.baseurl}}/Accessibility:_Testing_Howto#Strongwind" title="Accessibility: Testing Howto">Strongwind</a> and <a href="{{site.baseurl}}/Accessibility:_Testing_Howto#Orca" title="Accessibility: Testing Howto">Orca Regression Tests</a> will be used for the automation scripts.<br /><br />
</li><li>No regularly scheduled meetings at this time<br /><br />
</li><li>Minor editing (grammar and spelling corrections) of this test plan can be done at any time.  Any change to the test plan that changes how the product will be tested shall be approved by the QA team who will determine if the changes are large enough to require a change to the test plan identifier.<br /><br />
</li><li>Black box and white box testing methods are both acceptable.  However, it is anticipated that black box testing will be the norm.<br /><br />
</li><li>Integration testing will involve the iterative testing of new developer code as it becomes available and it is integrated into the product.  System testing will begin after provider and client pieces has been implemented and released.<br /><br />
</li><li>Smoke tests will be performed and will consist of (1) ensuring that the newest packages provided by the build team install successfully and (2) ensuring basic functionality and sanity of the newest packages.<br /><br />
</li><li>Exit criteria has yet to be established.  This should be discussed with project management.<br /><br />
</li><li>At this time, Orca and Accerciser are the standard tools to be used to test the accessibility of an application.  The Orca test harness and Strongwind will be used to automate accessibility tests.<br /><br />
</li><li>Run sample with UISpy in Windows system as reference to ensure we implement the similar accessibility.<br /><br />
</li><li>Run Gtk sample with Accerciser in Linux system as reference to ensure we implemnet the similar accessibility.<br /><br />
</li><li>Log bug into bugzilla, add bug reference like "#BUGxxxx: xxxxxxxx" into automated test suite and comment out the test case if test case is failing. Delete bug reference and uncomment test case till bug is closed.<br /><br />
</li></ul>
<h4> <span class="mw-headline" id="Item_pass.2Ffail_criteria"><u>Item pass/fail criteria</u></span></h4>
<p>The pass/fail criteria for each of the items described in Test Items section.
</p><p>Criteria for Test Components:
</p>
<table class="wikitable" border="1" style="text-align:center">

<tr>
<th> Test Items<br />
</th>
<th> Pass
</th>
<th> Fail
</th></tr>
<tr>
<td> Winforms Providers
</td>
<td>&#160;?
</td>
<td>
</td></tr>
<tr>
<td> Moonlight Providers
</td>
<td>&#160;?
</td>
<td>
</td></tr>
<tr>
<td> Core-Provider
</td>
<td>&#160;?
</td>
<td>
</td></tr>
<tr>
<td> Core-Client
</td>
<td>&#160;?
</td>
<td>
</td></tr>
<tr>
<td> ATKBridge
</td>
<td>&#160;?
</td>
<td>
</td></tr>
<tr>
<td> ATSPIBridge
</td>
<td>&#160;?
</td>
<td>
</td></tr>
</table>
<p>Individual test case pass/fail criterion is defined by the automated script which performs the testing.  Upon failure of a test case, the script should will log the failure.  For exit criteria, see <a href="{{site.baseurl}}/Accessibility:_Test_Plan#Approach" title="Accessibility: Test Plan">Approach</a>.
</p>
<h4> <span class="mw-headline" id="Suspension_criteria_and_resumption_requirements"><u>Suspension criteria and resumption requirements</u></span></h4>
<p>Suspension criteria:
</p>
<ul><li>Unavailability of external dependency during execution.
</li><li>When a defect is introduced that cannot allow any further testing (i.e., a blocker bug).
</li><li>Critical path deadline is missed so that the client will not accept delivery even if all testing is completed.
</li><li>A specific holiday shuts down both development and testing.
</li><li>Lack of testing resources (e.g., testers, hardware, etc).
</li></ul>
<p>Resumption requirements:
</p>
<ul><li>When the external dependent systems become available again.
</li><li>When a fix is successfully implemented and the testing team is notified to continue testing.
</li><li>The contract is renegotiated with the client to extend delivery.
</li><li>The holiday period ends.
</li><li>Testing resources become available
</li></ul>
<p>A failed build would not constitute suspension as we could generally continue to use the previous build. Major or critical defects would also not constitute suspension as other areas of the system could continue to be tested.
</p>
<h4> <span class="mw-headline" id="Test_deliverables"><u>Test deliverables</u></span></h4>
<p><i>All documents, tools, and other components that are to be developed and maintained in support of the testing effort</i>
</p>
<ul><li> Test plan (this document)
</li><li> Test cases - test cases are been included into test scripts
</li><li> Custom tools - test harness, test scripts, sample applications
</li><li> Defect reports - none at this time
</li><li> Test summary reports - dashboard web page
</li><li> Other - none at this time
</li></ul>
<h4> <span class="mw-headline" id="Testing_preparation_and_setup"><u>Testing preparation and setup</u></span></h4>
<p><i>set of tasks necessary to prepare for and perform testing</i>
</p><p>Team Setup:
</p>
<table class="wikitable" border="1" style="text-align:left">

<tr>
<th> Task<br />
</th>
<th> Finished
</th></tr>
<tr>
<td>Build UIAutomation project on Bugzilla and Testopia.
</td>
<td>X
</td></tr>
<tr>
<td>Prepare virtual machines for most recent releases of supported platforms (openSUSE, Ubuntu, Fedora)
</td>
<td>X
</td></tr>
<tr>
<td>Setup test environment on VMs
</td>
<td>X
</td></tr>
<tr>
<td>Obtain testable build
</td>
<td>X
</td></tr>
<tr>
<td>Build DashBoard for Test Summary Report
</td>
<td>P
</td></tr></table>
<p>X = Done
P = In Progress
</p><p>Individual Preparation:
</p>
<ul><li>Enable assistive technologies on the GNOME desktop.  This is done from "Assistive Technology Preferences" from the GNOME Control Center.
</li><li>Create Novell Bugzilla account
</li><li>Install Accerciser on OS
</li><li>Install most recent Mono
</li><li>Install most recent Orca
</li><li>Install most recent Strongwind
</li><li>Install Python &gt;=2.5
</li><li>Install Iron Python (IPCE) &gt;=1.1 
</li><li>Setup Windows os(Vista) with UISpy on VM if necessary
</li></ul>
<h4> <span class="mw-headline" id="Environmental_needs"><u>Environmental needs</u></span></h4>
<p><i>Hardware, software, data, interfaces, facilities, publications, other requirements that pertain to the testing effort</i>
</p><p>Testing may be done on physical and virtual machines.
</p><p>All tests must be performed on the most recent official release of the following platforms:
</p>
<table class="wikitable" border="1" style="text-align:center">

<tr>
<th>Product
</th>
<th>openSUSE 11.1
</th>
<th>openSUSE 11.2
</th>
<th>SLED 11
</th>
<th>Fedora 12
</th>
<th>Ubuntu 9.10 Karmic Koala
</th>
<th>openSUSE 11.3
</th>
<th>Fedora 13
</th></tr>
<tr>
<td> Moonlight ATK Bridge
</td>
<td>
</td>
<td> x
</td>
<td>
</td>
<td> x
</td>
<td> x
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<td> Winforms ATK Bridge
</td>
<td> x
</td>
<td> x
</td>
<td> x
</td>
<td> x
</td>
<td> x
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<td> Client API project
</td>
<td> x
</td>
<td> x
</td>
<td> x
</td>
<td> x
</td>
<td> x
</td>
<td>
</td>
<td>
</td></tr></table>
<p>&lt;/br&gt;
</p>
<table class="wikitable" border="1" style="text-align:center">

<tr>
<th>
</th>
<th> x86
</th>
<th> x86_64
</th></tr>
<tr>
<td> openSUSE
</td>
<td> X
</td>
<td> X
</td></tr>
<tr>
<td> SLED
</td>
<td> X
</td>
<td> X
</td></tr>
<tr>
<td> Fedora
</td>
<td> X
</td>
<td> X
</td></tr>
<tr>
<td> Ubuntu
</td>
<td> X
</td>
<td> X
</td></tr></table>
<p>Hardware:
</p>
<ul><li>No specific hardware requirements at this time
</li></ul>
<p>Software:
</p>
<ul><li>Mono - most recent release
</li><li>Accerciser - most recent package for your platform
</li><li>Orca - most recent package for your platform 
</li><li>Python &gt;=2.5
</li><li>IronPython (IPCE) - most recent package for your platform
</li><li>Strongwind - most recent release
</li></ul>
<h4> <span class="mw-headline" id="Responsibilities"><u>Responsibilities</u></span></h4>
<ul><li>All testers can work wherever they are needed, however, below is where our team focuses their efforts at this time:
</li></ul>
<h5> <span class="mw-headline" id="Test_Suit">Test Suit</span></h5>
<p>Test Harness:  Brian<br /><br />
DashBoard: Brian, Neville<br /><br />
</p>
<h5> <span class="mw-headline" id="WinForms_2">WinForms</span></h5>
<p>Strongwind Tests: Brian, Calen, Ray<br /><br />
Orca Tests: Brian<br /><br />
Smoke Tests: Brian<br /><br />
Sample Applications: Calen, Ray <br /><br />
</p>
<h5> <span class="mw-headline" id="MoonLight_2">MoonLight</span></h5>
<p>Sample Applications: Calen, Neville<br /><br />
Strongwind Tests:: Calen, Neville<br /><br />
</p>
<h5> <span class="mw-headline" id="UIAutomation_Client_API">UIAutomation Client API</span></h5>
<p>White Tests: Ray, Felicia<br /><br />
</p>
<h4> <span class="mw-headline" id="Staffing_and_training_needs"><u>Staffing and training needs</u></span></h4>
<ul><li> QA Automation Engineer (4)
<ul><li> Solid programming experience (C#, Python are a bonus)
</li><li> QA Engineer experience
</li><li> Bugzilla experience is a bonus
</li><li> Iterative testing experience is a bonus
</li></ul>
</li></ul>
<h5> <span class="mw-headline" id="Training_Plan">Training Plan</span></h5>
<table class="wikitable" border="1" style="text-align:left">

<tr>
<th>Time
</th>
<th>Contents
</th>
<th>Author
</th></tr>
<tr>
<td>Oct 19
</td>
<td>C# Introduction
</td>
<td>Matt
</td></tr>
<tr>
<td>Oct 23
</td>
<td>C# Introduction
</td>
<td>Matt
</td></tr>
<tr>
<td>Oct 30
</td>
<td>C# Introduction
</td>
<td>Matt
</td></tr>
</table>
<p>Everyone in the open source community is encouraged to join our QA team!
</p>
<h4> <span class="mw-headline" id="Schedule"><u>Schedule</u></span></h4>
<p><i>Built around the <a href="{{site.baseurl}}/Accessibility:_Roadmap" title="Accessibility: Roadmap">roadmap</a> but specific to testing with testing milestones</i>
</p>
<h5> <span class="mw-headline" id="WinForms_3">WinForms</span></h5>
<p>Based on  Q2 in roadmap, our initial testing schedule is below:
</p>
<table class="wikitable" border="1" style="text-align:left">

<tr>
<th> Task
</th>
<th> Start Time
</th>
<th> End Time
</th>
<th> Owner
</th></tr>
<tr>
<td> Design test plan
</td>
<td> Mar.
</td>
<td> Apr.
</td>
<td> Brian &amp; Calen
</td></tr>
<tr>
<td> Prepare test environmental stuff(OS, VM, App samples)
</td>
<td> Mar.
</td>
<td>
</td>
<td> Brian &amp; Calen
</td></tr>
<tr>
<td> Set up test environment
</td>
<td> Apr.
</td>
<td> May.
</td>
<td> Brian &amp; Calen
</td></tr>
<tr>
<td> Design test case and test samples
</td>
<td> Apr.
</td>
<td> Jun.
</td>
<td> Brian &amp; Calen &amp; Ray
</td></tr>
<tr>
<td> Automate smoke tests
</td>
<td> Sep. 10 2008
</td>
<td> Sep. 12 2008
</td>
<td> Brian
</td></tr>
<tr>
<td> Design Strongwind test, Run testcase and submit defect (release 0.9)
</td>
<td> July
</td>
<td> Nov
</td>
<td> Calen &amp; Brian
</td></tr>
<tr>
<td> Design Strongwind test, Run testcase and submit defect (release 1.0 BETA)
</td>
<td> Dec
</td>
<td> Jan
</td>
<td> Calen &amp; Brian &amp; Ray
</td></tr>
<tr>
<td> Design Strongwind test, Run testcase and submit defect (release 1.0 FINAL)
</td>
<td> Jan
</td>
<td> March 16 2009
</td>
<td> Calen &amp; Brian &amp; Ray
</td></tr>
<tr>
<td> Review Strongwind test, expand test cases
</td>
<td> April
</td>
<td> Jun
</td>
<td> Brian &amp; Author
</td></tr>
<tr>
<td> Build DashBoard
</td>
<td> May
</td>
<td> Jun
</td>
<td> Brian &amp; Neville
</td></tr>
<tr>
<td> Finish test report
</td>
<td>
</td>
<td>
</td>
<td> Brian &amp; Calen
</td></tr>
</table>
<h5> <span class="mw-headline" id="MoonLight_3">MoonLight</span></h5>
<table class="wikitable" border="1" style="text-align:left">

<tr>
<th> Task
</th>
<th> Start Time
</th>
<th> End Time
</th>
<th> Owner
</th></tr>
<tr>
<td> Design test plan
</td>
<td> Aug. 6
</td>
<td> Aug. 7
</td>
<td> Calen &amp; Neville
</td></tr>
<tr>
<td> create application samples
</td>
<td> Aug. 10
</td>
<td> Aug. 31
</td>
<td> Calen &amp; Neville
</td></tr>
<tr>
<td> Write and Review Strongwind tests for each control(5 weeks)
</td>
<td> Sep. 1
</td>
<td> Oct. 16(10.1-10.11 are national holiday)
</td>
<td> Calen &amp; Neville
</td></tr>
<tr>
<td> Run tests and log bugs(3 weeks)
</td>
<td> Oct. 19
</td>
<td> Nov. 6
</td>
<td> Calen &amp; Neville
</td></tr>
<tr>
<td> test one or two Real Moonlight app(1 week)
</td>
<td> Nov. 9
</td>
<td> Nov. 13
</td>
<td> Calen &amp; Neville
</td></tr>
<tr>
<td> test report(add moonlight test to dashbard)(1 week)
</td>
<td> Nov. 9
</td>
<td> Nov. 13
</td>
<td> Calen &amp; Neville
</td></tr>
</table>
<h5> <span class="mw-headline" id="Client_API">Client API</span></h5>
<table class="wikitable" border="1" style="text-align:left">

<tr>
<th> Task
</th>
<th> Start Time
</th>
<th> End Time
</th>
<th> Owner
</th></tr>
<tr>
<td> Design test plan
</td>
<td> Aug. 6
</td>
<td> Aug. 14
</td>
<td> Calen &amp; Ray
</td></tr>
<tr>
<td> Study how to use White to write tests
</td>
<td> Aug. 6
</td>
<td> Aug. 14
</td>
<td> Ray &amp; Felicia
</td></tr>
<tr>
<td> Study C# and UIA ClientAPI(4 weeks)
</td>
<td> Aug. 17
</td>
<td> Sep. 11
</td>
<td> Ray &amp; Felicia
</td></tr>
<tr>
<td> Create UIA ClientAPI UserCases and Tests for WinForms real app(KeePass)
</td>
<td> Sep. 14
</td>
<td> Oct. 30(10.1-10.11 are national holiday)
</td>
<td> Ray &amp; Felicia
</td></tr>
<tr>
<td> Run UIA ClientAPI tests and log bugs for Winforms(KeePass)
</td>
<td> Nov. 2
</td>
<td> Nov. 9
</td>
<td> Ray &amp; Felicia
</td></tr>
<tr>
<td> Create UIA ClientAPI UserCases and Tests for Moonlight real apps
</td>
<td>
</td>
<td>
</td>
<td> Neville &amp; Calen
</td></tr>
<tr>
<td> Run UIA ClientAPI tests and log bugs for Moonlight real apps
</td>
<td>
</td>
<td>
</td>
<td> Neville &amp; Calen
</td></tr>
<tr>
<td> Create UIA ClientAPI UserCases and tests for GTK+ real app(Tomboy, Tasque?)
</td>
<td>
</td>
<td>
</td>
<td> Felicia
</td></tr>
<tr>
<td> Run UIA ClientAPI tests and log bugs for GTK+ real app(Tomboy, Tasque?)
</td>
<td>
</td>
<td>
</td>
<td> Ray &amp; Felicia
</td></tr>
<tr>
<td> Finish test report
</td>
<td>
</td>
<td>
</td>
<td> Calen &amp; Neville &amp; Ray &amp; Felicia
</td></tr>
</table>
<h4> <span class="mw-headline" id="Risks_and_contingencies"><u>Risks and contingencies</u></span></h4>
<p><i>Any activity that jeopardizes the testing schedule is a planning risk</i>
</p>
<ul><li> Program release schedule delay will jeopardizes testing schedule
</li><li> Program quality of release version couldn't satisfy with acceptance criteria
</li><li> Test environmental stuff unobtainable easily
</li><li> Delays in necessary QA training (e.g., understanding what needs to be tested, writing sample applications, test tools, and automation scripts)
</li><li> Tester staff change or lack of tester resources
</li><li> Changes to the original requirements or Designs
</li><li> Frequent program design changes
</li><li> Loss of support from Novell/Microsoft upper management
</li></ul>
<h4> <span class="mw-headline" id="Approvals"><u>Approvals</u></span></h4>
<p><i>Persons who declare that the software is ready to move to the next stage</i>
</p><p>Brian Merrell<br />
Calen Chen<br />
Brad Taylor<br />
</p>
